{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a783c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbeb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../data/X_train.csv')\n",
    "df_drift = pd.read_csv('../../data/X_drift.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5297eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22481 entries, 0 to 22480\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   PolicyId           22481 non-null  object \n",
      " 1   AgeConducteur      22481 non-null  float64\n",
      " 2   SexeConducteur     22481 non-null  object \n",
      " 3   StatutMatrimonial  7372 non-null   object \n",
      " 4   BonusMalus         22481 non-null  float64\n",
      " 5   FrequencePaiement  22481 non-null  object \n",
      " 6   CodeProfession     7372 non-null   object \n",
      " 7   AgeVehicule        22481 non-null  float64\n",
      " 8   ClasseVehicule     22481 non-null  object \n",
      " 9   PuissanceVehicule  22481 non-null  object \n",
      " 10  CarburantVehicule  22481 non-null  object \n",
      " 11  UsageVehicule      22481 non-null  object \n",
      " 12  Garage             22481 non-null  object \n",
      " 13  Region             22481 non-null  object \n",
      " 14  PrimeCommerciale   22481 non-null  float64\n",
      "dtypes: float64(4), object(11)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2422ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22481 entries, 0 to 22480\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   PolicyId           22481 non-null  object \n",
      " 1   AgeConducteur      22481 non-null  float64\n",
      " 2   SexeConducteur     22481 non-null  object \n",
      " 3   StatutMatrimonial  7372 non-null   object \n",
      " 4   BonusMalus         22481 non-null  float64\n",
      " 5   FrequencePaiement  22481 non-null  object \n",
      " 6   CodeProfession     7372 non-null   object \n",
      " 7   AgeVehicule        22481 non-null  float64\n",
      " 8   ClasseVehicule     22481 non-null  object \n",
      " 9   PuissanceVehicule  22481 non-null  object \n",
      " 10  CarburantVehicule  22481 non-null  object \n",
      " 11  UsageVehicule      22481 non-null  object \n",
      " 12  Garage             22481 non-null  object \n",
      " 13  Region             22481 non-null  object \n",
      " 14  PrimeCommerciale   22481 non-null  float64\n",
      "dtypes: float64(4), object(11)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_drift.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drfit analysis \n",
    "\n",
    "\" add a binary target column to indicate source dataset in train and drift datasets\"\n",
    "df_train['source'] = 0\n",
    "df_drift['source'] = 1\n",
    "df_combined = pd.concat([df_train, df_drift], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f039cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d54bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7dfeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Xgboost classifier to detect drift tanks to AUC-ROC score\n",
    "X = df_combined.drop('source', axis=1)\n",
    "y = df_combined['source']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd532ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f880b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC-ROC score for drift detection: {auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frouros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8b1c1ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'DistanceResult'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m         val \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# On s'assure que c'est bien un float pur\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     psi_scores[col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 2. Affichage propre\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColonne\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatut\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'DistanceResult'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from frouros.detectors.data_drift.batch import PSI\n",
    "\n",
    "# 1. SÃ©lection des colonnes numÃ©riques\n",
    "columns = df_train.select_dtypes(include=['number']).columns\n",
    "psi_scores = {}\n",
    "\n",
    "for col in columns:\n",
    "    detector = PSI()\n",
    "    detector.fit(X=df_train[col].values)\n",
    "    result = detector.compare(X=df_drift[col].values)\n",
    "    \n",
    "    # --- EXTRACTION ULTRA-ROBUSTE ---\n",
    "    # On vÃ©rifie si l'objet a un attribut 'distance', sinon on prend le premier Ã©lÃ©ment\n",
    "    if hasattr(result, 'distance'):\n",
    "        val = result.distance\n",
    "    elif isinstance(result, (list, tuple)):\n",
    "        val = result[0]\n",
    "    else:\n",
    "        # Au cas oÃ¹ l'objet est dÃ©jÃ  un nombre ou autre chose\n",
    "        val = result\n",
    "        \n",
    "    # On s'assure que c'est bien un float pur\n",
    "    psi_scores[col] = float(val)\n",
    "\n",
    "# 2. Affichage propre\n",
    "print(f\"{'Colonne':<20} | {'PSI':<10} | {'Statut'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for col, score in psi_scores.items():\n",
    "    if score >= 0.25:\n",
    "        status = \"ðŸ”´ Drift Majeur\"\n",
    "    elif score >= 0.1:\n",
    "        status = \"ðŸŸ¡ Warning (DÃ©rive)\"\n",
    "    else:\n",
    "        status = \"ðŸŸ¢ Stable\"\n",
    "        \n",
    "    print(f\"{col:<20} | {score:.4f}     | {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37793056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8f7889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÃ©sultats PSI:\n",
      "          colonne         type    psi  missing_ref_%  missing_curr_%                   interpretation\n",
      "         PolicyId catÃ©gorielle 0.0000           0.00            0.00        Pas de drift significatif\n",
      "    AgeConducteur    numÃ©rique 0.6408           0.00            0.00 Drift important - action requise\n",
      "   SexeConducteur catÃ©gorielle 0.0000           0.00            0.00        Pas de drift significatif\n",
      "StatutMatrimonial catÃ©gorielle 0.0000          67.21           67.21        Pas de drift significatif\n",
      "       BonusMalus    numÃ©rique 2.0399           0.00            0.00 Drift important - action requise\n",
      "FrequencePaiement catÃ©gorielle 1.6564           0.00            0.00 Drift important - action requise\n",
      "   CodeProfession catÃ©gorielle 0.0000          67.21           67.21        Pas de drift significatif\n",
      "      AgeVehicule    numÃ©rique 2.7682           0.00            0.00 Drift important - action requise\n",
      "   ClasseVehicule catÃ©gorielle 7.3463           0.00            0.00 Drift important - action requise\n",
      "PuissanceVehicule catÃ©gorielle 0.0000           0.00            0.00        Pas de drift significatif\n",
      "CarburantVehicule catÃ©gorielle 0.0000           0.00            0.00        Pas de drift significatif\n",
      "    UsageVehicule catÃ©gorielle 0.0000           0.00            0.00        Pas de drift significatif\n",
      "           Garage catÃ©gorielle 0.0000           0.00            0.00        Pas de drift significatif\n",
      "           Region catÃ©gorielle 0.0000           0.00            0.00        Pas de drift significatif\n",
      " PrimeCommerciale    numÃ©rique 0.3494           0.00            0.00 Drift important - action requise\n",
      "\n",
      "Seuils d'interprÃ©tation:\n",
      "- PSI < 0.1  : Pas de drift\n",
      "- PSI < 0.2  : Drift modÃ©rÃ©\n",
      "- PSI >= 0.2 : Drift important\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, List, Optional\n",
    "\n",
    "def calculate_psi(dataset1: pd.DataFrame, \n",
    "                  dataset2: pd.DataFrame, \n",
    "                  columns: Union[str, List[str]], \n",
    "                  bins: int = 10,\n",
    "                  epsilon: float = 1e-10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calcule le Population Stability Index (PSI) entre deux datasets.\n",
    "    \n",
    "    ParamÃ¨tres:\n",
    "    -----------\n",
    "    dataset1 : pd.DataFrame\n",
    "        Dataset de rÃ©fÃ©rence (baseline/training)\n",
    "    dataset2 : pd.DataFrame\n",
    "        Dataset Ã  comparer (test/production)\n",
    "    columns : str ou List[str]\n",
    "        Nom(s) de(s) colonne(s) Ã  analyser\n",
    "    bins : int\n",
    "        Nombre de bins pour les variables numÃ©riques (dÃ©faut: 10)\n",
    "    epsilon : float\n",
    "        Petite valeur pour Ã©viter division par zÃ©ro (dÃ©faut: 1e-10)\n",
    "    \n",
    "    Retourne:\n",
    "    ---------\n",
    "    pd.DataFrame : RÃ©sultats PSI pour chaque colonne\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convertir columns en liste si c'est une seule colonne\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # VÃ©rifier que les colonnes existent\n",
    "    missing_cols = set(columns) - set(dataset1.columns) - set(dataset2.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Colonnes manquantes: {missing_cols}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for col in columns:\n",
    "        # Extraire les colonnes\n",
    "        ref = dataset1[col].copy()\n",
    "        curr = dataset2[col].copy()\n",
    "        \n",
    "        # Identifier le type de colonne\n",
    "        is_numeric = pd.api.types.is_numeric_dtype(ref) and pd.api.types.is_numeric_dtype(curr)\n",
    "        \n",
    "        # SÃ©parer valeurs manquantes et non-manquantes\n",
    "        ref_missing_count = ref.isna().sum()\n",
    "        curr_missing_count = curr.isna().sum()\n",
    "        \n",
    "        ref_valid = ref.dropna()\n",
    "        curr_valid = curr.dropna()\n",
    "        \n",
    "        # Si tout est manquant, PSI = 0\n",
    "        if len(ref_valid) == 0 and len(curr_valid) == 0:\n",
    "            results.append({\n",
    "                'colonne': col,\n",
    "                'type': 'vide',\n",
    "                'psi': 0.0,\n",
    "                'missing_ref_%': 100.0,\n",
    "                'missing_curr_%': 100.0,\n",
    "                'interpretation': 'Pas de drift (tout manquant)'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Calculer PSI pour les valeurs non-manquantes\n",
    "        if is_numeric:\n",
    "            psi_value = _calculate_psi_numeric(ref_valid, curr_valid, bins, epsilon)\n",
    "            col_type = 'numÃ©rique'\n",
    "        else:\n",
    "            psi_value = _calculate_psi_categorical(ref_valid, curr_valid, epsilon)\n",
    "            col_type = 'catÃ©gorielle'\n",
    "        \n",
    "        # Calculer PSI pour les missing values\n",
    "        ref_total = len(ref)\n",
    "        curr_total = len(curr)\n",
    "        \n",
    "        ref_missing_pct = ref_missing_count / ref_total if ref_total > 0 else 0\n",
    "        curr_missing_pct = curr_missing_count / curr_total if curr_total > 0 else 0\n",
    "        \n",
    "        # Ajouter contribution des missing au PSI total\n",
    "        if ref_missing_pct > 0 or curr_missing_pct > 0:\n",
    "            ref_missing_pct = max(ref_missing_pct, epsilon)\n",
    "            curr_missing_pct = max(curr_missing_pct, epsilon)\n",
    "            psi_missing = (curr_missing_pct - ref_missing_pct) * np.log(curr_missing_pct / ref_missing_pct)\n",
    "            psi_value += psi_missing\n",
    "        \n",
    "        # InterprÃ©tation du PSI\n",
    "        interpretation = _interpret_psi(psi_value)\n",
    "        \n",
    "        results.append({\n",
    "            'colonne': col,\n",
    "            'type': col_type,\n",
    "            'psi': round(psi_value, 4),\n",
    "            'missing_ref_%': round(ref_missing_pct * 100, 2),\n",
    "            'missing_curr_%': round(curr_missing_pct * 100, 2),\n",
    "            'interpretation': interpretation\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def _calculate_psi_numeric(ref: pd.Series, curr: pd.Series, bins: int, epsilon: float) -> float:\n",
    "    \"\"\"Calcule PSI pour variables numÃ©riques.\"\"\"\n",
    "    \n",
    "    # CrÃ©er les bins sur la distribution de rÃ©fÃ©rence\n",
    "    try:\n",
    "        _, bin_edges = np.histogram(ref, bins=bins)\n",
    "    except:\n",
    "        # Si problÃ¨me avec histogram, utiliser quantiles\n",
    "        bin_edges = np.percentile(ref, np.linspace(0, 100, bins + 1))\n",
    "    \n",
    "    # S'assurer que les bins couvrent les valeurs actuelles\n",
    "    bin_edges[0] = min(bin_edges[0], curr.min()) - epsilon\n",
    "    bin_edges[-1] = max(bin_edges[-1], curr.max()) + epsilon\n",
    "    \n",
    "    # Calculer distributions\n",
    "    ref_counts, _ = np.histogram(ref, bins=bin_edges)\n",
    "    curr_counts, _ = np.histogram(curr, bins=bin_edges)\n",
    "    \n",
    "    # Convertir en proportions\n",
    "    ref_props = ref_counts / len(ref)\n",
    "    curr_props = curr_counts / len(curr)\n",
    "    \n",
    "    # Ajouter epsilon pour Ã©viter log(0)\n",
    "    ref_props = np.where(ref_props == 0, epsilon, ref_props)\n",
    "    curr_props = np.where(curr_props == 0, epsilon, curr_props)\n",
    "    \n",
    "    # Calculer PSI\n",
    "    psi = np.sum((curr_props - ref_props) * np.log(curr_props / ref_props))\n",
    "    \n",
    "    return psi\n",
    "\n",
    "\n",
    "def _calculate_psi_categorical(ref: pd.Series, curr: pd.Series, epsilon: float) -> float:\n",
    "    \"\"\"Calcule PSI pour variables catÃ©gorielles.\"\"\"\n",
    "    \n",
    "    # Obtenir toutes les catÃ©gories uniques\n",
    "    all_categories = set(ref.unique()) | set(curr.unique())\n",
    "    \n",
    "    # Calculer distributions\n",
    "    ref_counts = ref.value_counts()\n",
    "    curr_counts = curr.value_counts()\n",
    "    \n",
    "    psi = 0.0\n",
    "    \n",
    "    for cat in all_categories:\n",
    "        ref_prop = ref_counts.get(cat, 0) / len(ref)\n",
    "        curr_prop = curr_counts.get(cat, 0) / len(curr)\n",
    "        \n",
    "        # Ajouter epsilon pour Ã©viter log(0)\n",
    "        ref_prop = max(ref_prop, epsilon)\n",
    "        curr_prop = max(curr_prop, epsilon)\n",
    "        \n",
    "        psi += (curr_prop - ref_prop) * np.log(curr_prop / ref_prop)\n",
    "    \n",
    "    return psi\n",
    "\n",
    "\n",
    "def _interpret_psi(psi: float) -> str:\n",
    "    \"\"\"InterprÃ¨te la valeur du PSI.\"\"\"\n",
    "    if psi < 0.1:\n",
    "        return \"Pas de drift significatif\"\n",
    "    elif psi < 0.2:\n",
    "        return \"Drift modÃ©rÃ© - surveillance recommandÃ©e\"\n",
    "    else:\n",
    "        return \"Drift important - action requise\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Calculer PSI\n",
    "    psi_results = calculate_psi(\n",
    "        dataset1=df_train,\n",
    "        dataset2=df_drift,\n",
    "        columns=df_train.columns.tolist(),\n",
    "        bins=10\n",
    "    )\n",
    "    \n",
    "    print(\"RÃ©sultats PSI:\")\n",
    "    print(psi_results.to_string(index=False))\n",
    "    print(\"\\nSeuils d'interprÃ©tation:\")\n",
    "    print(\"- PSI < 0.1  : Pas de drift\")\n",
    "    print(\"- PSI < 0.2  : Drift modÃ©rÃ©\")\n",
    "    print(\"- PSI >= 0.2 : Drift important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e987aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "    '''Calculate the PSI (population stability index) across all variables\n",
    "\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       mwburke.github.io.com\n",
    "    '''\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        '''Calculate the PSI for a single variable\n",
    "\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        '''\n",
    "\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "\n",
    "        if buckettype == 'bins':\n",
    "            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        elif buckettype == 'quantiles':\n",
    "            breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n",
    "\n",
    "        expected_fractions = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_fractions = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            '''Calculate the actual PSI value from comparing the values.\n",
    "               Update the actual value to a very small number if equal to zero\n",
    "            '''\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    "        psi_value = sum(sub_psi(expected_fractions[i], actual_fractions[i]) for i in range(0, len(expected_fractions)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[1 - axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = psi(expected, actual, buckets)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n",
    "\n",
    "    return(psi_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2777701e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PolicyId',\n",
       " 'AgeConducteur',\n",
       " 'SexeConducteur',\n",
       " 'StatutMatrimonial',\n",
       " 'BonusMalus',\n",
       " 'FrequencePaiement',\n",
       " 'CodeProfession',\n",
       " 'AgeVehicule',\n",
       " 'ClasseVehicule',\n",
       " 'PuissanceVehicule',\n",
       " 'CarburantVehicule',\n",
       " 'UsageVehicule',\n",
       " 'Garage',\n",
       " 'Region',\n",
       " 'PrimeCommerciale']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=df_train.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7c0a2b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Exemple d'utilisation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m psi_results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_psi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_drift\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 75\u001b[0m, in \u001b[0;36mcalculate_psi\u001b[1;34m(expected, actual, buckettype, buckets, axis)\u001b[0m\n\u001b[0;32m     73\u001b[0m     psi_values \u001b[38;5;241m=\u001b[39m psi(expected, actual, buckets)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     psi_values[i] \u001b[38;5;241m=\u001b[39m psi(\u001b[43mexpected\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, actual[:,i], buckets)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     77\u001b[0m     psi_values[i] \u001b[38;5;241m=\u001b[39m psi(expected[i,:], actual[i,:], buckets)\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3824\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3824\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3825\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6072\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   6068\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   6069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   6070\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   6071\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 6072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "psi_results = calculate_psi(df_train, df_drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a74a6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PolicyId': 0.0,\n",
       " 'AgeConducteur': 1.0563529912497733,\n",
       " 'SexeConducteur': 0.0,\n",
       " 'StatutMatrimonial': 0.0,\n",
       " 'BonusMalus': 8.71912037523559,\n",
       " 'FrequencePaiement': 0.6060633207404427,\n",
       " 'CodeProfession': 0.0,\n",
       " 'AgeVehicule': 3.4394590487522683,\n",
       " 'ClasseVehicule': 2.4441539238701915,\n",
       " 'PuissanceVehicule': 0.0,\n",
       " 'CarburantVehicule': 0.0,\n",
       " 'UsageVehicule': 0.0,\n",
       " 'Garage': 0.0,\n",
       " 'Region': 0.0,\n",
       " 'PrimeCommerciale': 1.4379520858825219}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skorecard.reporting import psi\n",
    "from skorecard.bucketers import DecisionTreeBucketer\n",
    "\n",
    "# AprÃ¨s bucketing des donnÃ©es\n",
    "psi_dict = psi(df_train, df_drift)\n",
    "psi_dict "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
